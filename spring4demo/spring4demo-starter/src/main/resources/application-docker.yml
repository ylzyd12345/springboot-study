# Docker 环境配置
spring:
  config:
    activate:
      on-profile: docker
  
  # 数据源配置
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:mysql://mysql:3306/spring4demo?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true}
    username: ${SPRING_DATASOURCE_USERNAME:spring4demo}
    password: ${SPRING_DATASOURCE_PASSWORD:spring4demo}
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      initial-size: 10
      min-idle: 10
      max-active: 50
      max-wait: 60000
      time-between-eviction-runs-millis: 60000
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 1
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      pool-prepared-statements: true
      max-pool-prepared-statement-per-connection-size: 20
      filters: stat,wall
      connection-properties: druid.stat.mergeSql=false;druid.stat.slowSqlMillis=2000
      web-stat-filter:
        enabled: false
      stat-view-servlet:
        enabled: false
  
  # Redis配置
  data:
    redis:
      host: ${SPRING_DATA_REDIS_HOST:redis}
      port: ${SPRING_DATA_REDIS_PORT:6379}
      password: ${SPRING_DATA_REDIS_PASSWORD:}
      database: 0
      lettuce:
        pool:
          max-active: 32
          max-wait: -1ms
          max-idle: 16
          min-idle: 8
        timeout: 10000ms
        
  # RabbitMQ配置
  rabbitmq:
    host: ${SPRING_RABBITMQ_HOST:rabbitmq}
    port: ${SPRING_RABBITMQ_PORT:5672}
    username: ${SPRING_RABBITMQ_USERNAME:admin}
    password: ${SPRING_RABBITMQ_PASSWORD:admin}
    virtual-host: ${SPRING_RABBITMQ_VIRTUAL_HOST:spring4demo}
    connection-timeout: 15000
    publisher-confirm-type: correlated
    publisher-returns: true
    listener:
      simple:
        acknowledge-mode: manual
        retry:
          enabled: true
          initial-interval: 1000
          max-attempts: 3
          max-interval: 10000
          multiplier: 1.0
  
  # Kafka配置
  kafka:
    bootstrap-servers: ${SPRING_KAFKA_BOOTSTRAP_SERVERS:kafka:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
      batch-size: 16384
      linger-ms: 1
      buffer-memory: 33554432
    consumer:
      group-id: spring4demo-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: false
      max-poll-records: 500
  
  # Elasticsearch配置
  elasticsearch:
    uris: ${SPRING_ELASTICSEARCH_URIS:http://elasticsearch:9200}
    username: ""
    password: ""
    connection-timeout: 5s
    socket-timeout: 30s

# 日志配置
logging:
  level:
    root: info
    com.kev1n.spring4demo: info
    org.springframework.web: info
    org.springframework.security: warn
  pattern:
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{traceId:-},%X{userId:-}] %logger{50} - %msg%n"
  file:
    name: /app/logs/spring4demo-docker.log
    
# MyBatis-Plus配置
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true
    cache-enabled: true
    call-seters-on-nulls: false
    jdbc-type-for-null: 'null'
  global-config:
    db-config:
      id-type: assign_id
      logic-delete-field: deleted
      logic-delete-value: 1
      logic-not-delete-value: 0
      table-underline: true
  mapper-locations: classpath*:mapper/**/*.xml
  type-aliases-package: com.kev1n.spring4demo.core.entity
    
# 管理端点配置
management:
  endpoints:
    web:
      exposure:
        include: ${MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE:health,info,metrics,prometheus}
  endpoint:
    health:
      show-details: always
  metrics:
    export:
      prometheus:
        enabled: ${MANAGEMENT_METRICS_EXPORT_PROMETHEUS_ENABLED:true}
        
# Docker 环境特殊配置
server:
  port: 8080
  servlet:
    context-path: /
  tomcat:
    max-threads: 800
    accept-count: 1000
    min-spare-threads: 100
    connection-timeout: 5000
    
# 缓存配置
  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=1000,expireAfterAccess=3600s
      
# 异步任务配置
  task:
    execution:
      pool:
        core-size: 20
        max-size: 100
        queue-capacity: 1000
        keep-alive: 60s
        thread-name-prefix: async-task-
    scheduling:
      pool:
        size: 10
        thread-name-prefix: scheduled-task-
        
# Docker 环境安全配置
security:
  headers:
    frame-options: DENY
    content-type-options: nosniff
    xss-protection: "1; mode=block"